Newsgroups: perl.jobs
Path: nntp.perl.org
Xref: nntp.perl.org perl.jobs:8482
Return-Path: <ask@perl.org>
Mailing-List: contact jobs-help@perl.org; run by ezmlm
Delivered-To: mailing list jobs@perl.org
Delivered-To: moderator for jobs@perl.org
Received: (qmail 10424 invoked from network); 24 Jul 2008 07:09:48 -0000
Received: from x1a.develooper.com (HELO x1.develooper.com) (216.52.237.111)
  by x6.develooper.com with SMTP; 24 Jul 2008 07:09:48 -0000
Received: (qmail 18870 invoked by uid 225); 24 Jul 2008 07:09:48 -0000
Delivered-To: jobs@perl.org
Received: (qmail 18864 invoked by alias); 24 Jul 2008 07:09:47 -0000
X-Spam-Status: No, hits=-10.6 required=8.0
	tests=BAYES_00,RCVD_IN_DNSWL_HI
X-Spam-Check-By: la.mx.develooper.com
Received: from x3.develooper.com (HELO x3.develooper.com) (63.251.223.163)
    by la.mx.develooper.com (qpsmtpd/0.28) with ESMTP; Thu, 24 Jul 2008 00:09:44 -0700
Received: by x3.develooper.com (Postfix, from userid 513)
	id B93492AFE4; Thu, 24 Jul 2008 00:09:40 -0700 (PDT)
To: jobs@perl.org
Message-ID: <20080724070940.B93492AFE4@x3.develooper.com>
Date: Thu, 24 Jul 2008 00:09:40 -0700 (PDT)
Subject: Data Engineer (Perl Expert) (onsite), United States, CA, San Francisco
Approved: news@nntp.perl.org
From: jobs-admin@perl.org (Perl Jobs)

Online URL for this job: http://jobs.perl.org/job/9260

To subscribe to this list, send mail to jobs-subscribe@perl.org.
To unsubscribe, send mail to jobs-unsubscribe@perl.org.

Posted: July 22, 2008

Job title: Data Engineer (Perl Expert)

Company name: Searchme

Location: United States, CA, San Francisco

Pay rate: DOE US$

Travel: 0%

Terms of employment: Salaried employee

Length of employment: na

Hours: Full time

Onsite: yes

Description:
Our search engine can exploit structured data (i.e. lists, feeds) to do a
better job in returning the best web content for a query. The more
structured data we can feed into the system, the better we can refine the
results flowing out. Your job will be to lead the effort in harnessing the
structured data available on the web, and making this data available
throughout the Searchme system. 
Specifically, you will help define and build infrastructure for gathering
data from many sources (web sites, RSS feeds, etc.) and then making this
data programmatically accessible to various client components within the
Searchme back end. 

Consider the following tasks: 
* Write a program to extract the list of current Academy Award winners and
update the existing list in a MySQL database instance. 
* Given an RSS feed, write a program to check the feed daily and extract
the title attributes from the stream and dump them into a text file. 

If you are already thinking about how these tasks could be a) better
specified and b) easily automated, then this might be a challenging,
rewarding job for you. 


Required skills:
Skills/Experience/Education: 

* Perl, Linux, and the ability to write programs that extract data from web
sites. 
* You should have experience with text parsing. 
* You don’t need to be an expert in SQL, but should be comfortable with
getting data into and out of MySQL databases. 
* Familiarity with RSS/Atom is a plus, as is basic C/C++ programming
skills. 

I


Desired skills:
deal Candidates: 

•	Have a keen interest in search technology, consumer internet and
next generation web technologies 
•	Have the ability to solve complex problems and desire to work with
large-scale, world-class infrastructure and applications 
•	Thrive in the n-state - an entrepreneurial environment unfettered
by bureaucracy and structure where every day brings new challenges 
•	Are a self-starter who wants to make a big impact quickly 
•	Demonstrate outstanding written and verbal communication 
•	Can lead several critical projects to completion 
•	Show detail-orientation, planning, problem solving and
organizational skills as well as a dogged, whatever-it-takes attitude 
•	Have a PhD or significant experience in a research environment 


URL for more information: http://www.searchme.com/

Contact information at:
http://jobs.perl.org/job/9260#contact


